<!doctype html>
<html lang="ja">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>ペットボトル認識Webアプリ</title>
    <style>
      :root {
        color-scheme: light;
      }
      body {
        margin: 0;
        font-family: "Hiragino Kaku Gothic ProN", "Yu Gothic", Meiryo, sans-serif;
        background: #f3f3f3;
        color: #1a1a1a;
      }
      .app {
        max-width: 960px;
        margin: 0 auto;
        padding: 24px 16px 32px;
      }
      .controls {
        display: flex;
        align-items: center;
        gap: 16px;
        margin-bottom: 16px;
      }
      .status {
        padding: 6px 12px;
        background: #fff;
        border-radius: 999px;
        border: 1px solid #d0d0d0;
        font-size: 14px;
      }
      button {
        padding: 10px 16px;
        font-size: 16px;
        border-radius: 8px;
        border: none;
        background: #111;
        color: #fff;
        cursor: pointer;
      }
      button:disabled {
        opacity: 0.6;
        cursor: not-allowed;
      }
      .stage {
        position: relative;
        width: 100%;
        max-width: 960px;
        margin: 0 auto;
        background: #000;
        border-radius: 12px;
        overflow: hidden;
        aspect-ratio: 4 / 3;
      }
      video,
      canvas {
        position: absolute;
        inset: 0;
        width: 100%;
        height: 100%;
      }
      video {
        object-fit: cover;
      }
    </style>
  </head>
  <body>
    <div class="app">
      <h1>ペットボトル認識Webアプリ</h1>
      <div class="controls">
        <button id="startButton" type="button">カメラ開始</button>
        <div class="status">状態: <span id="status">未許可</span></div>
        <div class="status">モデル: <span id="modelStatus">読み込み中</span></div>
      </div>
      <div class="stage">
        <video id="video" playsinline muted></video>
        <canvas id="overlay"></canvas>
      </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.16.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@2.2.3/dist/coco-ssd.min.js"></script>
    <script>
      const startButton = document.getElementById("startButton");
      const statusText = document.getElementById("status");
      const modelStatusText = document.getElementById("modelStatus");
      const video = document.getElementById("video");
      const overlay = document.getElementById("overlay");
      let activeStream = null;
      let model = null;
      let modelReady = false;
      let shouldRunInference = false;
      let inferenceTimer = null;
      let currentConfig = null;

      const setStatus = (value) => {
        statusText.textContent = value;
      };

      const setModelStatus = (value) => {
        modelStatusText.textContent = value;
      };

      const setButtonLabel = (isRunning) => {
        startButton.textContent = isRunning ? "カメラ終了" : "カメラ開始";
      };

      const loadConfig = async () => {
        const response = await fetch("../config/app.config.json", {
          cache: "no-store",
        });
        if (!response.ok) {
          throw new Error("config load failed");
        }
        return response.json();
      };

      const applyStream = (stream) => {
        if (activeStream) {
          activeStream.getTracks().forEach((track) => track.stop());
        }
        activeStream = stream;
        video.srcObject = stream;
      };

      const updateOverlaySize = () => {
        const { videoWidth, videoHeight } = video;
        if (!videoWidth || !videoHeight) {
          return;
        }
        overlay.width = videoWidth;
        overlay.height = videoHeight;
      };

      const clearOverlay = () => {
        const ctx = overlay.getContext("2d");
        ctx.clearRect(0, 0, overlay.width, overlay.height);
      };

      const getInferenceOptions = () => {
        const inference = (currentConfig && currentConfig.inference) || {};
        const ui = (currentConfig && currentConfig.ui) || {};
        return {
          intervalMs: inference.intervalMs ?? 250,
          scoreThreshold: inference.scoreThreshold ?? 0.6,
          targetClass: inference.targetClass || "bottle",
          showScore: ui.showScore === true,
          showCount: ui.showCount === true,
          showBoxes: ui.showBoxes !== false,
        };
      };

      const drawDetections = (detections, options) => {
        const ctx = overlay.getContext("2d");
        clearOverlay();
        ctx.lineWidth = 2;
        ctx.font = "14px sans-serif";
        ctx.textBaseline = "top";
        ctx.strokeStyle = "#00e5ff";
        ctx.fillStyle = "#00e5ff";

        if (options.showBoxes) {
          detections.forEach((detection) => {
            const [x, y, width, height] = detection.bbox;
            ctx.strokeRect(x, y, width, height);
            if (options.showScore) {
              const label = `${Math.round(detection.score * 100)}%`;
              ctx.fillText(label, x, Math.max(0, y - 18));
            }
          });
        }

        if (options.showCount) {
          ctx.fillText(`${options.targetClass}: ${detections.length}`, 12, 12);
        }
      };

      const stopInference = () => {
        shouldRunInference = false;
        if (inferenceTimer) {
          clearTimeout(inferenceTimer);
          inferenceTimer = null;
        }
      };

      const startInference = () => {
        if (!modelReady || !activeStream) {
          shouldRunInference = true;
          return;
        }
        if (inferenceTimer) {
          return;
        }
        shouldRunInference = true;
        const run = async () => {
          if (!shouldRunInference || !modelReady || !activeStream) {
            inferenceTimer = null;
            return;
          }
          updateOverlaySize();
          const options = getInferenceOptions();
          let predictions = [];
          try {
            predictions = await model.detect(video);
          } catch (error) {
            predictions = [];
          }
          const detections = predictions.filter(
            (prediction) =>
              prediction.class === options.targetClass &&
              prediction.score >= options.scoreThreshold
          );
          drawDetections(detections, options);
          inferenceTimer = setTimeout(run, options.intervalMs);
        };
        run();
      };

      const getStream = async (cameraConfig) => {
        const preferredConstraints = {
          audio: false,
          video: {
            width: cameraConfig.width,
            height: cameraConfig.height,
            facingMode: { ideal: cameraConfig.facingMode || "environment" },
          },
        };
        const fallbackConstraints = {
          audio: false,
          video: {
            width: cameraConfig.width,
            height: cameraConfig.height,
          },
        };

        try {
          return await navigator.mediaDevices.getUserMedia(preferredConstraints);
        } catch (error) {
          if (error && (error.name === "NotAllowedError" || error.name === "SecurityError")) {
            throw error;
          }
          return navigator.mediaDevices.getUserMedia(fallbackConstraints);
        }
      };

      const stopCamera = () => {
        if (activeStream) {
          activeStream.getTracks().forEach((track) => track.stop());
          activeStream = null;
        }
        stopInference();
        video.srcObject = null;
        clearOverlay();
        setStatus("停止中");
        setButtonLabel(false);
      };

      const startCamera = async () => {
        startButton.disabled = true;
        setStatus("起動中");

        try {
          const config = await loadConfig();
          currentConfig = config;
          const stream = await getStream(config.camera || {});
          applyStream(stream);
          await video.play();
          updateOverlaySize();
          setButtonLabel(true);
          startInference();
        } catch (error) {
          if (error && (error.name === "NotAllowedError" || error.name === "SecurityError")) {
            setStatus("未許可");
          } else {
            setStatus("失敗");
          }
          setButtonLabel(false);
        } finally {
          startButton.disabled = false;
        }
      };

      startButton.addEventListener("click", async () => {
        if (activeStream) {
          stopCamera();
          return;
        }
        await startCamera();
      });

      video.addEventListener("loadedmetadata", updateOverlaySize);
      window.addEventListener("resize", updateOverlaySize);

      const loadModel = async () => {
        setModelStatus("読み込み中");
        try {
          model = await cocoSsd.load();
          modelReady = true;
          setModelStatus("準備OK");
          if (shouldRunInference) {
            startInference();
          }
        } catch (error) {
          modelReady = false;
          setModelStatus("失敗");
        }
      };

      loadModel();
    </script>
  </body>
</html>
